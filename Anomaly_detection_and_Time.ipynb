{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Anomaly Detection? Explain its types (point, contextual, and\n",
        "collective anomalies) with examples.\n",
        "\n",
        "Answer: Anomaly Detection\n",
        "\n",
        "Anomaly Detection is a data analysis technique used to identify data points, patterns, or observations that deviate significantly from normal behavior. These unusual patterns are called anomalies or outliers and often indicate critical events such as fraud, system failures, intrusions, or errors.\n",
        "\n",
        "Types of Anomalies\n",
        "1. Point Anomalies\n",
        "\n",
        "A point anomaly occurs when a single data instance is significantly different from the rest of the data.\n",
        "\n",
        "Example:\n",
        "\n",
        "In a credit card transaction dataset, a transaction of ‚Çπ5,00,000 when the user usually spends ‚Çπ500‚Äì‚Çπ5,000.\n",
        "\n",
        "A sudden spike in temperature sensor data showing 120¬∞C when normal values are around 25‚Äì30¬∞C.\n",
        "\n",
        "üìå Most common and easiest type to detect.\n",
        "\n",
        "2. Contextual Anomalies\n",
        "\n",
        "A contextual anomaly is an observation that is anomalous only in a specific context (such as time, location, or season).\n",
        "\n",
        "Example:\n",
        "\n",
        "25¬∞C temperature is normal in summer but anomalous in winter.\n",
        "\n",
        "High website traffic at 2 PM is normal, but the same traffic at 3 AM may be anomalous.\n",
        "\n",
        "üìå Requires contextual information (time, location, environment).\n",
        "\n",
        "3. Collective Anomalies\n",
        "\n",
        "A collective anomaly occurs when a group of related data points is anomalous, even though individual points may appear normal.\n",
        "\n",
        "Example:\n",
        "\n",
        "A series of small network packets sent repeatedly could indicate a DDoS attack, even though each packet alone seems normal.\n",
        "\n",
        "Continuous small withdrawals from a bank account indicating fraudulent behavior.\n",
        "\n",
        "üìå Focuses on patterns rather than individual points."
      ],
      "metadata": {
        "id": "2zv-op6pSdYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Compare Isolation Forest, DBSCAN, and Local Outlier Factor in terms of\n",
        "their approach and suitable use cases.\n",
        "\n",
        "Answer: 1. Isolation Forest (iForest)\n",
        "\n",
        "Approach:\n",
        "\n",
        "Based on the idea that anomalies are easier to isolate than normal points.\n",
        "\n",
        "Uses an ensemble of random decision trees.\n",
        "\n",
        "Anomalies require fewer splits to be isolated in the trees.\n",
        "\n",
        "Key Characteristics:\n",
        "\n",
        "Does not rely on distance or density.\n",
        "\n",
        "Works well with high-dimensional data.\n",
        "\n",
        "Scales efficiently to large datasets.\n",
        "\n",
        "Suitable Use Cases:\n",
        "\n",
        "Fraud detection (credit card, insurance)\n",
        "\n",
        "Network intrusion detection\n",
        "\n",
        "High-dimensional datasets (logs, sensor data)\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Less interpretable\n",
        "\n",
        "May struggle with local anomalies in dense regions\n",
        "\n",
        "2. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
        "\n",
        "Approach:\n",
        "\n",
        "A density-based clustering algorithm.\n",
        "\n",
        "Points in low-density regions are labeled as noise (anomalies).\n",
        "\n",
        "Uses two parameters: eps (neighborhood radius) and min_samples.\n",
        "\n",
        "Key Characteristics:\n",
        "\n",
        "Identifies arbitrarily shaped clusters.\n",
        "\n",
        "Does not require specifying the number of clusters.\n",
        "\n",
        "Sensitive to parameter selection.\n",
        "\n",
        "Suitable Use Cases:\n",
        "\n",
        "Spatial data analysis\n",
        "\n",
        "Geographical data\n",
        "\n",
        "Datasets with clear density differences\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Poor performance in high-dimensional data\n",
        "\n",
        "Struggles with varying density clusters\n",
        "\n",
        "3. Local Outlier Factor (LOF)\n",
        "\n",
        "Approach:\n",
        "\n",
        "Measures local density deviation of a point compared to its neighbors.\n",
        "\n",
        "Points with significantly lower density than neighbors are flagged as anomalies.\n",
        "\n",
        "Key Characteristics:\n",
        "\n",
        "Excellent at detecting local anomalies.\n",
        "\n",
        "Distance-based and neighborhood-sensitive.\n",
        "\n",
        "Provides an outlier score (LOF score).\n",
        "\n",
        "Suitable Use Cases:\n",
        "\n",
        "Detecting subtle, local outliers\n",
        "\n",
        "Datasets with varying densities\n",
        "\n",
        "Time-series and spatial datasets\n",
        "\n",
        "Limitations:\n",
        "\n",
        "Computationally expensive\n",
        "\n",
        "Sensitive to choice of k (number of neighbors)\n",
        "\n",
        "Comparison Table\n",
        "Aspect\tIsolation Forest\tDBSCAN\tLocal Outlier Factor\n",
        "Core Idea\tIsolation via random splits\tDensity-based clustering\tLocal density comparison\n",
        "Type\tTree-based\tDensity-based\tDensity-based\n",
        "Handles High Dimensions\t‚úÖ Yes\t‚ùå No\t‚ùå Limited\n",
        "Detects Local Outliers\t‚ö†Ô∏è Limited\t‚ùå No\t‚úÖ Yes\n",
        "Scalability\tHigh\tMedium\tLow‚ÄìMedium\n",
        "Key Parameters\tn_estimators, contamination\teps, min_samples\tn_neighbors\n",
        "Output\tAnomaly score\tClusters + noise\tLOF score"
      ],
      "metadata": {
        "id": "0w93XxW4Sgwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What are the key components of a Time Series? Explain each with one\n",
        "example.\n",
        "\n",
        "Answer: 1. Trend (T)\n",
        "\n",
        "The trend represents the long-term movement or overall direction of the data over time.\n",
        "\n",
        "Example:\n",
        "\n",
        "A company‚Äôs annual sales increasing steadily over the last 10 years.\n",
        "\n",
        "Rising average global temperature over decades.\n",
        "\n",
        "üìà Shows long-term growth or decline.\n",
        "\n",
        "2. Seasonality (S)\n",
        "\n",
        "Seasonality refers to regular and repeating patterns at fixed intervals due to seasonal factors.\n",
        "\n",
        "Example:\n",
        "\n",
        "Ice cream sales increase every summer and decrease in winter.\n",
        "\n",
        "Higher electricity consumption during daytime hours.\n",
        "\n",
        "üîÅ Occurs at known, fixed intervals.\n",
        "\n",
        "3. Cyclical Component (C)\n",
        "\n",
        "The cyclical component represents long-term fluctuations that do not have a fixed or regular period, often influenced by economic or business cycles.\n",
        "\n",
        "Example:\n",
        "\n",
        "Economic expansions and recessions affecting employment rates.\n",
        "\n",
        "Real estate market ups and downs over several years.\n",
        "\n",
        "üîÑ Period and amplitude are not fixed.\n",
        "\n",
        "4. Irregular / Random Component (R)\n",
        "\n",
        "The irregular (random) component captures unpredictable, random variations caused by unexpected events.\n",
        "\n",
        "Example:\n",
        "\n",
        "A sudden drop in airline bookings due to a pandemic.\n",
        "\n",
        "Stock price fluctuations caused by breaking news.\n",
        "\n",
        "‚ö° Noise that cannot be predicted easily."
      ],
      "metadata": {
        "id": "fnGPxmM1THlj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Define Stationary in time series. How can you test and transform a\n",
        "non-stationary series into a stationary one?\n",
        "\n",
        "Answer: Stationarity in Time Series\n",
        "\n",
        "A time series is said to be stationary if its statistical properties remain constant over time.\n",
        "This means the series has:\n",
        "\n",
        "Constant mean\n",
        "\n",
        "Constant variance\n",
        "\n",
        "Constant autocovariance (correlation structure)\n",
        "\n",
        "Stationarity is important because many time-series models (like ARIMA) assume the data is stationary.\n",
        "\n",
        "How to Test Stationarity\n",
        "1. Visual Inspection\n",
        "\n",
        "Plot the time series.\n",
        "\n",
        "If the mean or variance changes over time, the series is likely non-stationary.\n",
        "\n",
        "Example:\n",
        "An upward-sloping sales plot indicates non-stationarity due to trend.\n",
        "\n",
        "2. Augmented Dickey‚ÄìFuller (ADF) Test\n",
        "\n",
        "Null hypothesis (H‚ÇÄ): Time series is non-stationary.\n",
        "\n",
        "Alternative hypothesis (H‚ÇÅ): Time series is stationary.\n",
        "\n",
        "Decision Rule:\n",
        "\n",
        "If p-value < 0.05, reject H‚ÇÄ ‚Üí series is stationary.\n",
        "\n",
        "If p-value ‚â• 0.05, series is non-stationary.\n",
        "\n",
        "3. KPSS Test\n",
        "\n",
        "Null hypothesis (H‚ÇÄ): Time series is stationary.\n",
        "\n",
        "Alternative hypothesis (H‚ÇÅ): Time series is non-stationary.\n",
        "\n",
        "üìå ADF and KPSS together give a more reliable conclusion.\n",
        "\n",
        "How to Transform a Non-Stationary Series into a Stationary One\n",
        "1. Differencing\n",
        "\n",
        "Subtract the previous observation from the current one.\n",
        "\n",
        "ùëå\n",
        "ùë°\n",
        "‚Ä≤\n",
        "=\n",
        "ùëå\n",
        "ùë°\n",
        "‚àí\n",
        "ùëå\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        "Y\n",
        "t\n",
        "‚Ä≤\n",
        "\t‚Äã\n",
        "\n",
        "=Y\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "‚àíY\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        "\n",
        "Removes trend\n",
        "\n",
        "First-order differencing is most common\n",
        "\n",
        "2. Log / Power Transformation\n",
        "Apply log, square root, or Box-Cox transformation.\n",
        "\n",
        "Stabilizes variance\n",
        "\n",
        "Useful when variance increases over time\n",
        "\n",
        "Example:\n",
        "\n",
        "ùëå\n",
        "ùë°\n",
        "‚Ä≤\n",
        "=\n",
        "log\n",
        "‚Å°\n",
        "(\n",
        "ùëå\n",
        "ùë°\n",
        ")\n",
        "Y\n",
        "t\n",
        "‚Ä≤\n",
        "\t‚Äã\n",
        "\n",
        "=log(Y\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        ")\n",
        "3. Detrending\n",
        "\n",
        "Remove the trend component using regression or smoothing.\n",
        "\n",
        "Useful when trend is deterministic\n",
        "\n",
        "4. Seasonal Differencing\n",
        "\n",
        "Subtract values from the same season.\n",
        "\n",
        "ùëå\n",
        "ùë°\n",
        "‚Ä≤\n",
        "=\n",
        "ùëå\n",
        "ùë°\n",
        "‚àí\n",
        "ùëå\n",
        "ùë°\n",
        "‚àí\n",
        "ùëö\n",
        "Y\n",
        "t\n",
        "‚Ä≤\n",
        "\t‚Äã\n",
        "\n",
        "=Y\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "‚àíY\n",
        "t‚àím\n",
        "\t‚Äã\n",
        "\n",
        "\n",
        "(where m is the seasonal period, e.g., 12 for monthly data)"
      ],
      "metadata": {
        "id": "fUuR2IykTasz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Differentiate between AR, MA, ARIMA, SARIMA, and SARIMAX models in\n",
        "terms of structure and application.\n",
        "\n",
        "Answer: 1. AR (AutoRegressive) Model\n",
        "\n",
        "Structure:\n",
        "\n",
        "ùëå\n",
        "ùë°\n",
        "=\n",
        "ùëê\n",
        "+\n",
        "ùúô\n",
        "1\n",
        "ùëå\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        "+\n",
        "ùúô\n",
        "2\n",
        "ùëå\n",
        "ùë°\n",
        "‚àí\n",
        "2\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "ùúô\n",
        "ùëù\n",
        "ùëå\n",
        "ùë°\n",
        "‚àí\n",
        "ùëù\n",
        "+\n",
        "ùúÄ\n",
        "ùë°\n",
        "Y\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=c+œï\n",
        "1\n",
        "\t‚Äã\n",
        "\n",
        "Y\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        "+œï\n",
        "2\n",
        "\t‚Äã\n",
        "\n",
        "Y\n",
        "t‚àí2\n",
        "\t‚Äã\n",
        "\n",
        "+‚ãØ+œï\n",
        "p\n",
        "\t‚Äã\n",
        "\n",
        "Y\n",
        "t‚àíp\n",
        "\t‚Äã\n",
        "\n",
        "+Œµ\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "\n",
        "Key Idea:\n",
        "\n",
        "Current value depends on past values of the series.\n",
        "\n",
        "Application:\n",
        "\n",
        "When the time series is stationary and shows strong autocorrelation.\n",
        "\n",
        "Example:\n",
        "\n",
        "Daily temperature forecasting.\n",
        "\n",
        "2. MA (Moving Average) Model\n",
        "\n",
        "Structure:\n",
        "\n",
        "ùëå\n",
        "ùë°\n",
        "=\n",
        "ùëê\n",
        "+\n",
        "ùúÄ\n",
        "ùë°\n",
        "+\n",
        "ùúÉ\n",
        "1\n",
        "ùúÄ\n",
        "ùë°\n",
        "‚àí\n",
        "1\n",
        "+\n",
        "ùúÉ\n",
        "2\n",
        "ùúÄ\n",
        "ùë°\n",
        "‚àí\n",
        "2\n",
        "+\n",
        "‚ãØ\n",
        "+\n",
        "ùúÉ\n",
        "ùëû\n",
        "ùúÄ\n",
        "ùë°\n",
        "‚àí\n",
        "ùëû\n",
        "Y\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "=c+Œµ\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "+Œ∏\n",
        "1\n",
        "\t‚Äã\n",
        "\n",
        "Œµ\n",
        "t‚àí1\n",
        "\t‚Äã\n",
        "\n",
        "+Œ∏\n",
        "2\n",
        "\t‚Äã\n",
        "\n",
        "Œµ\n",
        "t‚àí2\n",
        "\t‚Äã\n",
        "\n",
        "+‚ãØ+Œ∏\n",
        "q\n",
        "\t‚Äã\n",
        "\n",
        "Œµ\n",
        "t‚àíq\n",
        "\t‚Äã\n",
        "\n",
        "\n",
        "Key Idea:\n",
        "\n",
        "Current value depends on past error terms.\n",
        "\n",
        "Application:\n",
        "\n",
        "When past shocks/noise influence the series.\n",
        "\n",
        "Example:\n",
        "\n",
        "Modeling random demand fluctuations.\n",
        "\n",
        "3. ARIMA (AutoRegressive Integrated Moving Average)\n",
        "\n",
        "Structure:\n",
        "\n",
        "ùê¥\n",
        "ùëÖ\n",
        "ùêº\n",
        "ùëÄ\n",
        "ùê¥\n",
        "(\n",
        "ùëù\n",
        ",\n",
        "ùëë\n",
        ",\n",
        "ùëû\n",
        ")\n",
        "ARIMA(p,d,q)\n",
        "\n",
        "p: AR order\n",
        "\n",
        "d: Differencing order (to make series stationary)\n",
        "\n",
        "q: MA order\n",
        "\n",
        "Key Idea:\n",
        "\n",
        "Combines AR + differencing + MA.\n",
        "\n",
        "Application:\n",
        "\n",
        "Non-stationary time series without seasonality.\n",
        "\n",
        "Example:\n",
        "\n",
        "Sales forecasting with a trend.\n",
        "\n",
        "4. SARIMA (Seasonal ARIMA)\n",
        "\n",
        "Structure:\n",
        "\n",
        "ùëÜ\n",
        "ùê¥\n",
        "ùëÖ\n",
        "ùêº\n",
        "ùëÄ\n",
        "ùê¥\n",
        "(\n",
        "ùëù\n",
        ",\n",
        "ùëë\n",
        ",\n",
        "ùëû\n",
        ")\n",
        "(\n",
        "ùëÉ\n",
        ",\n",
        "ùê∑\n",
        ",\n",
        "ùëÑ\n",
        ")\n",
        "ùëö\n",
        "SARIMA(p,d,q)(P,D,Q)\n",
        "m\n",
        "\t‚Äã\n",
        "\n",
        "\n",
        "Adds seasonal AR, differencing, and MA components\n",
        "\n",
        "m: Seasonal period (e.g., 12 for monthly data)\n",
        "\n",
        "Key Idea:\n",
        "\n",
        "Captures seasonal patterns in time series.\n",
        "\n",
        "Application:\n",
        "\n",
        "Time series with trend and seasonality.\n",
        "\n",
        "Example:\n",
        "\n",
        "Monthly airline passenger data.\n",
        "\n",
        "5. SARIMAX (Seasonal ARIMA with Exogenous Variables)\n",
        "\n",
        "Structure:\n",
        "\n",
        "ùëÜ\n",
        "ùê¥\n",
        "ùëÖ\n",
        "ùêº\n",
        "ùëÄ\n",
        "ùê¥\n",
        "ùëã\n",
        "(\n",
        "ùëù\n",
        ",\n",
        "ùëë\n",
        ",\n",
        "ùëû\n",
        ")\n",
        "(\n",
        "ùëÉ\n",
        ",\n",
        "ùê∑\n",
        ",\n",
        "ùëÑ\n",
        ")\n",
        "ùëö\n",
        "+\n",
        "ùëã\n",
        "ùë°\n",
        "SARIMAX(p,d,q)(P,D,Q)\n",
        "m\n",
        "\t‚Äã\n",
        "\n",
        "+X\n",
        "t\n",
        "\t‚Äã\n",
        "\n",
        "\n",
        "Includes external (exogenous) variables\n",
        "\n",
        "Key Idea:\n",
        "\n",
        "Forecast depends on past values + seasonality + external factors.\n",
        "\n",
        "Application:\n",
        "\n",
        "When time series is influenced by other variables.\n",
        "\n",
        "Example:\n",
        "\n",
        "Sales forecasting using promotions and holidays.\n",
        "\n",
        "Comparison Table\n",
        "Model\tComponents\tSeasonality\tExternal Variables\tApplication\n",
        "AR\tPast values\t‚ùå No\t‚ùå No\tStationary data\n",
        "MA\tPast errors\t‚ùå No\t‚ùå No\tNoise-based patterns\n",
        "ARIMA\tAR + I + MA\t‚ùå No\t‚ùå No\tTrend, non-stationary\n",
        "SARIMA\tARIMA + seasonal\t‚úÖ Yes\t‚ùå No\tSeasonal time series\n",
        "SARIMAX\tSARIMA + exogenous\t‚úÖ Yes\t‚úÖ Yes\tSeasonal + external factors\n"
      ],
      "metadata": {
        "id": "pbggAT2zT31L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset:\n",
        "‚óè NYC Taxi Fare Data\n",
        "‚óè AirPassengers Dataset\n",
        "Question 6: Load a time series dataset (e.g., AirPassengers), plot the original series,\n",
        "and decompose it into trend, seasonality, and residual components.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Step 1: Import Required Libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "OVPHFEOBUGlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n"
      ],
      "metadata": {
        "id": "5CljsJN6Uk6k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load the AirPassengers Dataset"
      ],
      "metadata": {
        "id": "yTi9N-czUsBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
        ")\n",
        "\n",
        "# Convert Month column to datetime\n",
        "data['Month'] = pd.to_datetime(data['Month'])\n",
        "data.set_index('Month', inplace=True)\n",
        "\n",
        "# Rename column for convenience\n",
        "data.columns = ['Passengers']\n",
        "\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "TozicjpPSc29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Plot the Original Time Series"
      ],
      "metadata": {
        "id": "72M2WKZ-SRcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.plot(data, label='Air Passengers')\n",
        "plt.title('AirPassengers Time Series')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "Pq1ioMoBU2BM",
        "outputId": "2f990638-8aa7-4394-dfba-aad7af0074fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1987779620.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Air Passengers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AirPassengers Time Series'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of Passengers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Decompose the Time Series\n",
        "\n",
        "Since the variance increases with time, we use a multiplicative model."
      ],
      "metadata": {
        "id": "vVGdoK1cU_Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decomposition = seasonal_decompose(\n",
        "    data['Passengers'],\n",
        "    model='multiplicative',\n",
        "    period=12\n",
        ")\n",
        "\n",
        "decomposition.plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "eqRCwkPbVD9U",
        "outputId": "587470ad-b0de-4dd8-853e-cba0bf7ead2a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-945895249.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m decomposition = seasonal_decompose(\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Passengers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multiplicative'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Components Explanation\n",
        "1. Trend\n",
        "\n",
        "Shows long-term growth in air passengers.\n",
        "\n",
        "Reflects increasing air travel demand.\n",
        "\n",
        "2. Seasonality\n",
        "\n",
        "Repeating yearly pattern.\n",
        "\n",
        "Peaks during mid-year (holiday season).\n",
        "\n",
        "3. Residual (Irregular)\n",
        "\n",
        "Random fluctuations not explained by trend or seasonality.\n",
        "\n",
        "Contains noise and unexpected variations."
      ],
      "metadata": {
        "id": "WEjKrrhbVGwz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Apply Isolation Forest on a numerical dataset (e.g., NYC Taxi Fare) to\n",
        "detect anomalies. Visualize the anomalies on a 2D scatter plot.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Step 1: Import Required Libraries"
      ],
      "metadata": {
        "id": "wtXnvTBpVNe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n"
      ],
      "metadata": {
        "id": "ID12PZ3BVc2O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load and Prepare the Dataset\n",
        "\n",
        "(Assume a simplified NYC Taxi Fare dataset with numerical features)"
      ],
      "metadata": {
        "id": "lWZDM8wMVgaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample structure of NYC Taxi Fare data\n",
        "# Features: trip_distance, fare_amount\n",
        "data = pd.read_csv(\"nyc_taxi_fare.csv\")\n",
        "\n",
        "# Select numerical features\n",
        "X = data[['trip_distance', 'fare_amount']]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "THFMjBPuVkVz",
        "outputId": "55c2886a-c721-4ca1-81bf-51b56c6fe988"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'nyc_taxi_fare.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3574304684.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Sample structure of NYC Taxi Fare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Features: trip_distance, fare_amount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nyc_taxi_fare.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Select numerical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nyc_taxi_fare.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Apply Isolation Forest"
      ],
      "metadata": {
        "id": "kCzujUunVoA7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iso_forest = IsolationForest(\n",
        "    n_estimators=100,\n",
        "    contamination=0.05,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit and predict\n",
        "data['anomaly'] = iso_forest.fit_predict(X)\n",
        "\n",
        "# -1 ‚Üí anomaly, 1 ‚Üí normal\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "neTWGRC-VqsH",
        "outputId": "eab409c4-bf6d-46eb-e9a1-fc7d8d03d497"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1016378094.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Fit and predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'anomaly'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miso_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# -1 ‚Üí anomaly, 1 ‚Üí normal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Separate Normal Points and Anomalies"
      ],
      "metadata": {
        "id": "uSU949C6Vvj1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal = data[data['anomaly'] == 1]\n",
        "anomalies = data[data['anomaly'] == -1]\n"
      ],
      "metadata": {
        "id": "g8tF4W2kVy87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Visualize Anomalies (2D Scatter Plot)"
      ],
      "metadata": {
        "id": "7iGWA7ezV0yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(normal['trip_distance'], normal['fare_amount'], label='Normal', alpha=0.5)\n",
        "plt.scatter(anomalies['trip_distance'], anomalies['fare_amount'], label='Anomaly')\n",
        "plt.xlabel('Trip Distance')\n",
        "plt.ylabel('Fare Amount')\n",
        "plt.title('Isolation Forest ‚Äì NYC Taxi Fare Anomaly Detection')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2_f57399V3Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation of Results\n",
        "\n",
        "Normal points follow the expected fare‚Äìdistance relationship\n",
        "\n",
        "Anomalies include:\n",
        "\n",
        "Very high fare for short distance\n",
        "\n",
        "Unusually low fare for long distance\n",
        "\n",
        "These may indicate:\n",
        "\n",
        "Meter faults\n",
        "\n",
        "Data entry errors\n",
        "\n",
        "Fraudulent rides\n",
        "\n",
        "Why Isolation Forest Works Well Here\n",
        "\n",
        "NYC Taxi Fare data is large-scale\n",
        "\n",
        "Isolation Forest:\n",
        "\n",
        "Does not rely on distance or density\n",
        "\n",
        "Efficient for high-volume numerical data\n",
        "\n",
        "Isolates rare, abnormal observations quickly"
      ],
      "metadata": {
        "id": "ZEY8ks_GV8bL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Train a SARIMA model on the monthly airline passengers dataset.\n",
        "Forecast the next 12 months and visualize the results.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Step 1: Import Required Libraries"
      ],
      "metadata": {
        "id": "r-7yT8McWAJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n"
      ],
      "metadata": {
        "id": "9qVdSGRiWPCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Load the AirPassengers Dataset"
      ],
      "metadata": {
        "id": "NRQ_LvUjWQ-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
        ")\n",
        "\n",
        "# Convert to datetime\n",
        "data['Month'] = pd.to_datetime(data['Month'])\n",
        "data.set_index('Month', inplace=True)\n",
        "data.columns = ['Passengers']\n",
        "\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "id": "POcbpgz4WTdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Train the SARIMA Model\n",
        "\n",
        "AirPassengers data has:\n",
        "\n",
        "Trend\n",
        "\n",
        "Strong yearly seasonality (period = 12)\n",
        "\n",
        "We use:\n",
        "SARIMA(1,1,1)(1,1,1,12)"
      ],
      "metadata": {
        "id": "NonqQxCoWVnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SARIMAX(\n",
        "    data['Passengers'],\n",
        "    order=(1, 1, 1),\n",
        "    seasonal_order=(1, 1, 1, 12)\n",
        ")\n",
        "\n",
        "sarima_model = model.fit()\n",
        "print(sarima_model.summary())\n"
      ],
      "metadata": {
        "id": "TTSiG8eSWYlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Forecast the Next 12 Months"
      ],
      "metadata": {
        "id": "hDrElqmTWa_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forecast = sarima_model.get_forecast(steps=12)\n",
        "forecast_mean = forecast.predicted_mean\n",
        "forecast_ci = forecast.conf_int()\n"
      ],
      "metadata": {
        "id": "XgPr2PIsWdS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Visualize the Forecast"
      ],
      "metadata": {
        "id": "sRl2ptcAWfrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot original data\n",
        "plt.plot(data, label='Observed')\n",
        "\n",
        "# Plot forecast\n",
        "plt.plot(forecast_mean, label='Forecast', linestyle='--')\n",
        "\n",
        "# Confidence interval\n",
        "plt.fill_between(\n",
        "    forecast_ci.index,\n",
        "    forecast_ci.iloc[:, 0],\n",
        "    forecast_ci.iloc[:, 1],\n",
        "    alpha=0.3\n",
        ")\n",
        "\n",
        "plt.title('SARIMA Forecast ‚Äì AirPassengers Dataset')\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Number of Passengers')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "nHmr1z1ZWhrj",
        "outputId": "a690c670-966e-49d2-81fe-7f27999842aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-100249610.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plot original data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Observed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Plot forecast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Apply Local Outlier Factor (LOF) on any numerical dataset to detect\n",
        "anomalies and visualize them using matplotlib.\n",
        "\n",
        "Answer:\n",
        "\n",
        "Step 1: Import Required Libraries"
      ],
      "metadata": {
        "id": "zm9_zxhwWo-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n"
      ],
      "metadata": {
        "id": "Zf94XYAvW7d1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Create / Load a Numerical Dataset\n"
      ],
      "metadata": {
        "id": "iiMyi1kBW-E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Generate normal data\n",
        "X_normal = 0.3 * np.random.randn(200, 2)\n",
        "\n",
        "# Generate outliers\n",
        "X_outliers = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
        "\n",
        "# Combine data\n",
        "X = np.vstack((X_normal, X_outliers))\n",
        "\n",
        "data = pd.DataFrame(X, columns=['Feature1', 'Feature2'])\n"
      ],
      "metadata": {
        "id": "WY-NPCwwXFI7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Apply Local Outlier Factor (LOF)"
      ],
      "metadata": {
        "id": "pi08Cn-hXH4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lof = LocalOutlierFactor(\n",
        "    n_neighbors=20,\n",
        "    contamination=0.1\n",
        ")\n",
        "\n",
        "# Fit and predict\n",
        "data['anomaly'] = lof.fit_predict(data[['Feature1', 'Feature2']])\n",
        "\n",
        "# -1 ‚Üí anomaly, 1 ‚Üí normal\n"
      ],
      "metadata": {
        "id": "SE9thPcFXNPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Separate Normal Points and Anomalies"
      ],
      "metadata": {
        "id": "IaPV4-hhXO9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normal = data[data['anomaly'] == 1]\n",
        "anomalies = data[data['anomaly'] == -1]\n"
      ],
      "metadata": {
        "id": "lBO1oMj-XR57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Visualize Anomalies Using Matplotlib"
      ],
      "metadata": {
        "id": "YGZBrRnXXYGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.scatter(\n",
        "    normal['Feature1'], normal['Feature2'],\n",
        "    label='Normal', alpha=0.6\n",
        ")\n",
        "\n",
        "plt.scatter(\n",
        "    anomalies['Feature1'], anomalies['Feature2'],\n",
        "    label='Anomaly'\n",
        ")\n",
        "\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Local Outlier Factor (LOF) ‚Äì Anomaly Detection')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yyDIPV1sXeO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation of Results\n",
        "\n",
        "Normal points form dense clusters\n",
        "\n",
        "Anomalies lie in low-density regions\n",
        "\n",
        "LOF detects local density deviations, not just global outliers\n",
        "\n",
        "Why LOF is Useful\n",
        "\n",
        "Excellent for local anomalies\n",
        "\n",
        "Works well when:\n",
        "\n",
        "Data has varying densities\n",
        "\n",
        "Outliers are subtle and context-dependent"
      ],
      "metadata": {
        "id": "UY-XnHE6XjVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You are working as a data scientist for a power grid monitoring company.\n",
        "Your goal is to forecast energy demand and also detect abnormal spikes or drops in\n",
        "real-time consumption data collected every 15 minutes. The dataset includes features\n",
        "like timestamp, region, weather conditions, and energy usage.\n",
        "Explain your real-time data science workflow:\n",
        "‚óè How would you detect anomalies in this streaming data (Isolation Forest / LOF /\n",
        "DBSCAN)?\n",
        "‚óè Which time series model would you use for short-term forecasting (ARIMA /\n",
        "SARIMA / SARIMAX)?\n",
        "‚óè How would you validate and monitor the performance over time?\n",
        "‚óè How would this solution help business decisions or operations?\n",
        "\n",
        "Answer: 1. Real-Time Anomaly Detection (Streaming Data)\n",
        "Recommended Approach: Isolation Forest + LOF (Hybrid)\n",
        "Why not only DBSCAN?\n",
        "\n",
        "DBSCAN is not ideal for streaming data\n",
        "\n",
        "Sensitive to eps and min_samples\n",
        "\n",
        "Struggles with high-dimensional and evolving data\n",
        "\n",
        "Isolation Forest (Primary Detector)\n",
        "\n",
        "Why Isolation Forest?\n",
        "\n",
        "Fast and scalable for high-frequency (15-minute) data\n",
        "\n",
        "Works well with high-dimensional features\n",
        "\n",
        "Suitable for near real-time scoring\n",
        "\n",
        "Features used:\n",
        "\n",
        "Energy usage\n",
        "\n",
        "Temperature, humidity\n",
        "\n",
        "Hour of day, day of week\n",
        "\n",
        "Region-level aggregated demand\n",
        "\n",
        "What it detects:\n",
        "\n",
        "Sudden spikes or drops\n",
        "\n",
        "Meter faults\n",
        "\n",
        "Data ingestion errors\n",
        "\n",
        "Local Outlier Factor (Secondary Validator)\n",
        "\n",
        "Why LOF?\n",
        "\n",
        "Detects local anomalies\n",
        "\n",
        "Useful when:\n",
        "\n",
        "One region behaves abnormally compared to nearby regions\n",
        "\n",
        "Gradual drifts occur\n",
        "\n",
        "üìå Workflow:\n",
        "\n",
        "Isolation Forest flags anomalies first\n",
        "\n",
        "LOF confirms anomalies locally (reduces false positives)\n",
        "\n",
        "2. Short-Term Energy Demand Forecasting\n",
        "Recommended Model: SARIMAX\n",
        "Why SARIMAX?\n",
        "\n",
        "Energy demand has:\n",
        "\n",
        "Strong daily & weekly seasonality\n",
        "\n",
        "Dependence on external factors\n",
        "\n",
        "Model Structure:\n",
        "\n",
        "ùëÜ\n",
        "ùê¥\n",
        "ùëÖ\n",
        "ùêº\n",
        "ùëÄ\n",
        "ùê¥\n",
        "ùëã\n",
        "(\n",
        "ùëù\n",
        ",\n",
        "ùëë\n",
        ",\n",
        "ùëû\n",
        ")\n",
        "(\n",
        "ùëÉ\n",
        ",\n",
        "ùê∑\n",
        ",\n",
        "ùëÑ\n",
        ")\n",
        "ùëö\n",
        "+\n",
        "ùëã\n",
        "SARIMAX(p,d,q)(P,D,Q)\n",
        "m\n",
        "\t‚Äã\n",
        "\n",
        "+X\n",
        "\n",
        "Exogenous Variables (X):\n",
        "\n",
        "Temperature\n",
        "\n",
        "Humidity\n",
        "\n",
        "Weather events\n",
        "\n",
        "Holiday indicators\n",
        "\n",
        "üìå Forecast Horizon:\n",
        "\n",
        "Next 1‚Äì24 hours\n",
        "\n",
        "Next 1‚Äì7 days (short-term grid planning)\n",
        "\n",
        "Why not ARIMA or SARIMA alone?\n",
        "Model\tLimitation\n",
        "ARIMA\tNo seasonality, no external features\n",
        "SARIMA\tSeasonality yes, but ignores weather\n",
        "SARIMAX\t‚úî Seasonality + ‚úî Weather impact\n",
        "3. Validation & Performance Monitoring\n",
        "Forecast Validation\n",
        "\n",
        "Rolling / sliding window evaluation\n",
        "\n",
        "Metrics:\n",
        "\n",
        "MAE (Mean Absolute Error)\n",
        "\n",
        "RMSE\n",
        "\n",
        "MAPE\n",
        "\n",
        "Compare:\n",
        "\n",
        "Forecast vs actual demand per region\n",
        "\n",
        "Anomaly Detection Monitoring\n",
        "\n",
        "Track:\n",
        "\n",
        "Number of anomalies per day\n",
        "\n",
        "False positives confirmed by operators\n",
        "\n",
        "Periodically retrain models:\n",
        "\n",
        "Weekly or monthly\n",
        "\n",
        "Adapt to seasonal load changes\n",
        "\n",
        "Concept Drift Handling\n",
        "\n",
        "Monitor:\n",
        "\n",
        "Feature distributions\n",
        "\n",
        "Prediction error trends\n",
        "\n",
        "Retrain models if:\n",
        "\n",
        "Error increases beyond threshold\n",
        "\n",
        "Consumption patterns shift (policy changes, EV adoption)\n",
        "\n",
        "4. Business & Operational Impact\n",
        "Operational Benefits\n",
        "\n",
        "üö® Early fault detection\n",
        "\n",
        "Transformer failures\n",
        "\n",
        "Sensor malfunctions\n",
        "\n",
        "‚ö° Prevent blackouts\n",
        "\n",
        "Proactive load balancing\n",
        "\n",
        "üîß Predictive maintenance\n",
        "\n",
        "Reduce downtime\n",
        "\n",
        "Business Benefits\n",
        "\n",
        "üí∞ Cost optimization\n",
        "\n",
        "Efficient energy generation planning\n",
        "\n",
        "üìâ Reduced penalties\n",
        "\n",
        "Avoid overload fines\n",
        "\n",
        "üìä Regulatory compliance\n",
        "\n",
        "Accurate demand reporting\n",
        "\n",
        "Decision Support\n",
        "\n",
        "Real-time dashboards for grid operators\n",
        "\n",
        "Automated alerts for anomalies\n",
        "\n",
        "Data-driven capacity planning"
      ],
      "metadata": {
        "id": "OWrMpNZyXkkl"
      }
    }
  ]
}